#!/usr/bin/env python3

import sys
import os
import csv
import json
import whisper
import torch
import signal

def main():
    if len(sys.argv) != 2:
        print("Usage: transcribe <audio_file>")
        sys.exit(1)

    file_path = sys.argv[1]

    # Generate paths from audio file basename
    base_name = os.path.splitext(os.path.basename(file_path))[0]
    output_dir = os.path.join("output", base_name)
    timeline_file = os.path.join(output_dir, f"{base_name}_timeline.csv")
    metadata_file = os.path.join(output_dir, "metadata.json")
    audio_dir = os.path.join(output_dir, "audio")

    # Check if required files exist
    if not os.path.exists(timeline_file):
        print(f"Error: Timeline CSV not found: {timeline_file}")
        print("Run 'diarize' first to generate the timeline.")
        sys.exit(1)

    if not os.path.exists(audio_dir):
        print(f"Error: Audio segments directory not found: {audio_dir}")
        print("Run 'cut-audio' first to generate audio segments.")
        sys.exit(1)

    print("Transcribing audio segments...")

    # Load Whisper model with GPU detection
    device = "cuda" if torch.cuda.is_available() else "cpu"
    use_fp16 = device == "cuda"
    model = whisper.load_model("small", device=device, fp16=use_fp16)

    # Load metadata for language hints
    speaker_languages = {}
    if os.path.exists(metadata_file):
        with open(metadata_file, 'r') as f:
            metadata = json.load(f)
            for speaker, data in metadata.items():
                speaker_languages[speaker] = data.get("language", "en")

    # Load timeline data
    timeline_data = []
    with open(timeline_file, 'r') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            timeline_data.append(row)

    # Check for existing transcription to resume from
    transcription_file = os.path.join(output_dir, "transcription.csv")
    last_completed_segment = 0

    if os.path.exists(transcription_file):
        with open(transcription_file, 'r') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                segment_id = int(row['segment_id'])
                if segment_id > last_completed_segment:
                    last_completed_segment = segment_id
        print(f"Resuming transcription from segment {last_completed_segment + 1}")
    else:
        # Create new file with header
        with open(transcription_file, 'w', newline='') as csvfile:
            fieldnames = ['speaker_id', 'segment_id', 'start_time', 'end_time', 'text', 'language', 'confidence']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

    # Transcribe each audio segment
    transcribed_count = 0

    for i, timeline_row in enumerate(timeline_data, 1):
        # Skip already transcribed segments
        if i <= last_completed_segment:
            continue

        segment_file = os.path.join(audio_dir, f"{i:06d}.mp3")

        if not os.path.exists(segment_file):
            print(f"Warning: Audio segment {segment_file} not found")
            continue

        speaker_id = timeline_row['SPEAKER_ID']
        language = speaker_languages.get(speaker_id, "en")

        transcription_row = None

        try:
            def timeout_handler(signum, frame):
                raise TimeoutError("Transcription timeout")

            # Set timeout for individual segment (30 seconds per segment)
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(30)

            try:
                result = model.transcribe(segment_file, language=language)
                signal.alarm(0)  # Cancel timeout

                transcription_row = {
                    'speaker_id': speaker_id,
                    'segment_id': i,
                    'start_time': timeline_row['start_time'],
                    'end_time': timeline_row['end_time'],
                    'text': result['text'].strip(),
                    'language': language,
                    'confidence': float(result.get('segments', [{}])[0].get('avg_logprob', 0.0)) if result.get('segments') else 0.0
                }

                print(f"Transcribed segment {i:06d} ({speaker_id}): {result['text'].strip()[:50]}...")

            except TimeoutError:
                signal.alarm(0)  # Cancel timeout
                print(f"Timeout transcribing segment {i:06d} (30s limit exceeded)")
                transcription_row = {
                    'speaker_id': speaker_id,
                    'segment_id': i,
                    'start_time': timeline_row['start_time'],
                    'end_time': timeline_row['end_time'],
                    'text': "[TIMEOUT]",
                    'language': language,
                    'confidence': 0.0
                }

        except Exception as e:
            print(f"Error transcribing segment {i:06d}: {e}")
            transcription_row = {
                'speaker_id': speaker_id,
                'segment_id': i,
                'start_time': timeline_row['start_time'],
                'end_time': timeline_row['end_time'],
                'text': "",
                'language': language,
                'confidence': 0.0
            }

        # Write transcription result immediately to CSV
        if transcription_row:
            with open(transcription_file, 'a', newline='') as csvfile:
                fieldnames = ['speaker_id', 'segment_id', 'start_time', 'end_time', 'text', 'language', 'confidence']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writerow(transcription_row)
            transcribed_count += 1

    print(f"Transcription saved to: {transcription_file}")
    print(f"Transcribed {transcribed_count} new segments")

if __name__ == "__main__":
    main()